{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f370112b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, cv2, json, math, random, torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
        "from transformers import AutoImageProcessor, AutoModel\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1c76a01",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-10T23:52:45.347328Z",
          "iopub.status.busy": "2025-11-10T23:52:45.347097Z",
          "iopub.status.idle": "2025-11-11T01:39:56.040723Z",
          "shell.execute_reply": "2025-11-11T01:39:56.039613Z"
        },
        "papermill": {
          "duration": 6430.697833,
          "end_time": "2025-11-11T01:39:56.041865",
          "exception": false,
          "start_time": "2025-11-10T23:52:45.344032",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BASE_DIR  = \"./data\"\n",
        "AUTH_DIR  = f\"{BASE_DIR}/train_images/authentic\"\n",
        "FORG_DIR  = f\"{BASE_DIR}/train_images/forged\"\n",
        "MASK_DIR  = f\"{BASE_DIR}/train_masks\"\n",
        "TEST_DIR  = f\"{BASE_DIR}/test_images\"\n",
        "DINO_PATH = \"facebook/dinov2-base\"\n",
        "\n",
        "IMG_SIZE = 512\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS_SEG = 10\n",
        "LR_SEG = 1e-4\n",
        "WEIGHT_DECAY = 2e-5\n",
        "CHANNELS = 4\n",
        "\n",
        "class ForgerySegDataset(Dataset):\n",
        "    def __init__(self, auth_paths, forg_paths, mask_dir, img_size=256, transform=False):\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "        for p in forg_paths:\n",
        "            m = os.path.join(mask_dir, Path(p).stem + \".npy\")\n",
        "            if os.path.exists(m):\n",
        "                self.samples.append((p, m))\n",
        "        for p in auth_paths:\n",
        "            self.samples.append((p, None))\n",
        "        self.img_size = img_size\n",
        "        \n",
        "        # Define transforms once in __init__, not in __getitem__\n",
        "        if self.transform:\n",
        "            self.aug = A.Compose([\n",
        "                A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "                # Geometric augmentations\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.VerticalFlip(p=0.5),\n",
        "                A.RandomRotate90(p=0.5),\n",
        "                # Color augmentations (important for generalization)\n",
        "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "                A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.3),\n",
        "                # Noise/blur (helps with real-world robustness)\n",
        "                A.GaussianBlur(blur_limit=(3, 5), p=0.2),\n",
        "                A.GaussNoise(var_limit=(10, 50), p=0.2),\n",
        "                # JPEG compression artifacts (very relevant for forgery detection!)\n",
        "                A.ImageCompression(quality_lower=70, quality_upper=100, p=0.3),\n",
        "                # Normalize and convert to tensor\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                ToTensorV2(),\n",
        "            ])\n",
        "        else:\n",
        "            self.aug = A.Compose([\n",
        "                A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                ToTensorV2(),\n",
        "            ])\n",
        "    \n",
        "    def __len__(self): \n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path, mask_path = self.samples[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img = np.array(img)  # Convert to numpy for albumentations\n",
        "        h, w = img.shape[:2]\n",
        "        \n",
        "        masks = np.zeros((h, w, CHANNELS), np.uint8)  # (H, W, C) for albumentations\n",
        "        if mask_path:\n",
        "            loaded_masks = np.load(mask_path)  # Shape: (num_masks, H, W)\n",
        "            len_masks = len(loaded_masks)\n",
        "            # Transpose to (H, W, C)\n",
        "            for i in range(min(len_masks, CHANNELS)):\n",
        "                masks[:, :, i] = loaded_masks[i]\n",
        "        \n",
        "        # Apply transforms\n",
        "        transformed = self.aug(image=img, mask=masks)\n",
        "        img_t = transformed['image']  # Already a tensor with shape (C, H, W)\n",
        "        masks_t = transformed['mask']  # Shape: (H, W, C)\n",
        "        \n",
        "        # Transpose mask back to (C, H, W)\n",
        "        if isinstance(masks_t, np.ndarray):\n",
        "            masks_t = torch.from_numpy(masks_t.astype(np.float32)).permute(2, 0, 1)\n",
        "        else:\n",
        "            masks_t = masks_t.permute(2, 0, 1).float()\n",
        "        \n",
        "        return img_t, masks_t\n",
        "\n",
        "\n",
        "class DinoDecoder(nn.Module):\n",
        "    \"\"\"Progressive upsampling decoder with regularization\"\"\"\n",
        "    def __init__(self, in_ch=768, out_ch=CHANNELS, dropout=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Progressive upsampling: 37x37 â†’ 74 â†’ 148 â†’ 296 â†’ 512\n",
        "        self.up1 = self._block(in_ch, 384, dropout)    # 37 â†’ 74\n",
        "        self.up2 = self._block(384, 192, dropout)      # 74 â†’ 148\n",
        "        self.up3 = self._block(192, 96, dropout)       # 148 â†’ 296\n",
        "        self.up4 = self._block(96, 48, dropout)        # 296 â†’ 512 (final)\n",
        "        \n",
        "        self.final = nn.Conv2d(48, out_ch, kernel_size=1)\n",
        "    \n",
        "    def _block(self, in_ch, out_ch, dropout):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    \n",
        "    def forward(self, f, size):\n",
        "        # Progressive upsampling\n",
        "        x = F.interpolate(f, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = self.up1(x)\n",
        "        \n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = self.up2(x)\n",
        "        \n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = self.up3(x)\n",
        "        \n",
        "        x = F.interpolate(x, size=size, mode='bilinear', align_corners=False)\n",
        "        x = self.up4(x)\n",
        "        \n",
        "        return self.final(x)\n",
        "\n",
        "class DinoSegmenter(nn.Module):\n",
        "    def __init__(self, encoder, processor, unfreeze_blocks=3):\n",
        "        super().__init__()\n",
        "        self.encoder, self.processor = encoder, processor\n",
        "        \n",
        "        # Freeze all parameters first\n",
        "        for p in self.encoder.parameters():\n",
        "            p.requires_grad = False\n",
        "        \n",
        "        # Unfreeze the last N transformer blocks\n",
        "        num_blocks = len(self.encoder.encoder.layer)  # 12 for dinov2-base\n",
        "        for i in range(num_blocks - unfreeze_blocks, num_blocks):\n",
        "            for p in self.encoder.encoder.layer[i].parameters():\n",
        "                p.requires_grad = True\n",
        "        \n",
        "        # Optionally unfreeze the final layernorm\n",
        "        for p in self.encoder.layernorm.parameters():\n",
        "            p.requires_grad = True\n",
        "        \n",
        "        self.seg_head = DinoDecoder(768, CHANNELS)\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        imgs = (x*255).clamp(0,255).byte().permute(0,2,3,1).cpu().numpy()\n",
        "        inputs = self.processor(images=list(imgs), return_tensors=\"pt\").to(x.device)\n",
        "        # Remove torch.no_grad() since we're fine-tuning!\n",
        "        feats = self.encoder(**inputs).last_hidden_state\n",
        "        B, N, C = feats.shape\n",
        "        fmap = feats[:, 1:, :].permute(0, 2, 1)\n",
        "        s = int(math.sqrt(N-1))\n",
        "        fmap = fmap.reshape(B, C, s, s)\n",
        "        return fmap\n",
        "\n",
        "    def forward_seg(self, x):\n",
        "        fmap = self.forward_features(x)\n",
        "        return self.seg_head(fmap, (IMG_SIZE, IMG_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "723ba7d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "#  TRAINING\n",
        "#  MODEL (DINOv2 + Decoder)\n",
        "processor = AutoImageProcessor.from_pretrained(DINO_PATH)\n",
        "encoder = AutoModel.from_pretrained(DINO_PATH).eval().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e669b4db",
      "metadata": {},
      "outputs": [],
      "source": [
        "auth_imgs = sorted([str(Path(AUTH_DIR)/f) for f in os.listdir(AUTH_DIR)])\n",
        "forg_imgs = sorted([str(Path(FORG_DIR)/f) for f in os.listdir(FORG_DIR)])\n",
        "train_auth, val_auth = train_test_split(auth_imgs, test_size=0.2, random_state=42)\n",
        "train_forg, val_forg = train_test_split(forg_imgs, test_size=0.2, random_state=42)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    ForgerySegDataset(train_auth, train_forg, MASK_DIR, transform=True),  # <-- Enable augmentations!\n",
        "    batch_size=BATCH_SIZE, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    ForgerySegDataset(val_auth, val_forg, MASK_DIR, transform=False),  # <-- No augmentations for validation\n",
        "    batch_size=BATCH_SIZE, shuffle=False, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1dd7372",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_seg = DinoSegmenter(encoder, processor).to(device)\n",
        "# load weights\n",
        "# model_seg.load_state_dict(torch.load(\"model_seg_final.pt\"))\n",
        "\n",
        "# opt_seg = optim.AdamW(model_seg.seg_head.parameters(), lr=LR_SEG, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "# Separate parameter groups with different learning rates\n",
        "backbone_params = []\n",
        "decoder_params = []\n",
        "\n",
        "for name, param in model_seg.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        if 'seg_head' in name:\n",
        "            decoder_params.append(param)\n",
        "        else:\n",
        "            backbone_params.append(param)\n",
        "\n",
        "opt_seg = optim.AdamW([\n",
        "    {'params': backbone_params, 'lr': LR_SEG / 10},  # 10x smaller LR for backbone\n",
        "    {'params': decoder_params, 'lr': LR_SEG},\n",
        "], weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "pos_weight = torch.tensor([99.0]).to(device)  # Adjust this value\n",
        "crit_seg = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "# crit_seg = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# baseline\n",
        "# val_loss = .44, val_f1 = .17\n",
        "# augmented data: .1783 (10 epochs)\n",
        "# better model structure: val f1 = .23\n",
        "# hungarian matching: val f1 = 0.2645 (15 epochs, overfits with more epochs), reached 0.3100 with more epochs\n",
        "train_losses = []\n",
        "val_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b90d8ee6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "def hungarian_matched_loss(outputs, targets, pos_weight=None):\n",
        "    \"\"\"\n",
        "    Compute BCE loss with Hungarian matching between pred/gt channels.\n",
        "    \n",
        "    outputs: (B, C, H, W) - predicted logits\n",
        "    targets: (B, C, H, W) - ground truth masks\n",
        "    \"\"\"\n",
        "    B, C, H, W = outputs.shape\n",
        "    device = outputs.device\n",
        "    \n",
        "    matched_losses = []\n",
        "    \n",
        "    for b in range(B):\n",
        "        pred = outputs[b]  # (C, H, W)\n",
        "        tgt = targets[b]   # (C, H, W)\n",
        "        \n",
        "        # Build cost matrix: cost[i,j] = BCE(pred_channel_i, gt_channel_j)\n",
        "        with torch.no_grad():\n",
        "            cost_matrix = torch.zeros(C, C)\n",
        "            for i in range(C):\n",
        "                for j in range(C):\n",
        "                    cost_matrix[i, j] = F.binary_cross_entropy_with_logits(\n",
        "                        pred[i], tgt[j], \n",
        "                        pos_weight=pos_weight,\n",
        "                        reduction='mean'\n",
        "                    )\n",
        "        \n",
        "        # Hungarian matching (find optimal assignment)\n",
        "        row_ind, col_ind = linear_sum_assignment(cost_matrix.cpu().numpy())\n",
        "        \n",
        "        # Compute loss for matched pairs (WITH gradients this time)\n",
        "        for r, c in zip(row_ind, col_ind):\n",
        "            loss = F.binary_cross_entropy_with_logits(\n",
        "                pred[r], tgt[c],\n",
        "                pos_weight=pos_weight,\n",
        "                reduction='mean'\n",
        "            )\n",
        "            matched_losses.append(loss)\n",
        "    \n",
        "    return torch.stack(matched_losses).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e515117",
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot train and val losses\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Val Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74a43da7",
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS_SEG = 10\n",
        "for e in range(EPOCHS_SEG):\n",
        "    model_seg.train()\n",
        "    total_train_loss = 0\n",
        "    for x, m in tqdm(train_loader, desc=f\"[Segmentation] Epoch {e+1}/{EPOCHS_SEG}\"):\n",
        "        x, m = x.to(device), m.to(device)\n",
        "        outputs = model_seg.forward_seg(x)\n",
        "        loss = hungarian_matched_loss(outputs, m, pos_weight=pos_weight)\n",
        "        opt_seg.zero_grad()\n",
        "        loss.backward()\n",
        "        opt_seg.step()\n",
        "        total_train_loss += loss.item()\n",
        "    print(f\"  â†’ avg_loss={total_train_loss/len(train_loader):.4f}\")\n",
        "    train_losses.append(total_train_loss/len(train_loader))\n",
        "\n",
        "    # compute val loss\n",
        "    model_seg.eval()\n",
        "    total_val_loss = 0\n",
        "    for x, m in tqdm(val_loader, desc=\"Validation\"):\n",
        "        x, m = x.to(device), m.to(device)\n",
        "        outputs = model_seg.forward_seg(x)\n",
        "        loss = hungarian_matched_loss(outputs, m, pos_weight=pos_weight)\n",
        "        total_val_loss += loss.item()\n",
        "    print(f\"  â†’ avg_loss={total_val_loss/len(val_loader):.4f}\")\n",
        "    val_losses.append(total_val_loss/len(val_loader))\n",
        "\n",
        "torch.save(model_seg.state_dict(),\"model_seg_final.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0b3566a",
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def segment_prob_map_all_channels(pil):\n",
        "    \"\"\"Returns probability maps for ALL channels (not just channel 0).\"\"\"\n",
        "    x = torch.from_numpy(np.array(pil.resize((IMG_SIZE, IMG_SIZE)), np.float32)/255.).permute(2,0,1)[None].to(device)\n",
        "    return torch.sigmoid(model_seg.forward_seg(x))[0].cpu().numpy()  # Shape: (CHANNELS, H, W)\n",
        "\n",
        "def enhanced_adaptive_mask(prob, alpha_grad=0.35):\n",
        "    gx = cv2.Sobel(prob, cv2.CV_32F, 1, 0, ksize=3)\n",
        "    gy = cv2.Sobel(prob, cv2.CV_32F, 0, 1, ksize=3)\n",
        "    grad_mag = np.sqrt(gx**2 + gy**2)\n",
        "    grad_norm = grad_mag / (grad_mag.max() + 1e-6)\n",
        "    enhanced = (1 - alpha_grad) * prob + alpha_grad * grad_norm\n",
        "\n",
        "    enhanced = cv2.GaussianBlur(enhanced, (3,3), 0)\n",
        "\n",
        "    thr = np.mean(enhanced) + 0.3 * np.std(enhanced)\n",
        "    mask = (enhanced > thr).astype(np.uint8)\n",
        "\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
        "\n",
        "    return mask, thr\n",
        "\n",
        "def finalize_mask(prob, orig_size):\n",
        "    mask, thr = enhanced_adaptive_mask(prob)\n",
        "    mask = cv2.resize(mask, orig_size, interpolation=cv2.INTER_NEAREST)\n",
        "    return mask, thr\n",
        "\n",
        "def pipeline_final(pil):\n",
        "    \"\"\"Returns a LIST of masks (one per detected forged region) instead of a single merged mask.\"\"\"\n",
        "    probs = segment_prob_map_all_channels(pil)  # (CHANNELS, H, W)\n",
        "    \n",
        "    all_masks = []\n",
        "    all_areas = []\n",
        "    all_means = []\n",
        "    all_thrs = []\n",
        "    \n",
        "    for ch in range(probs.shape[0]):\n",
        "        prob = probs[ch]\n",
        "        mask, thr = finalize_mask(prob, pil.size)\n",
        "        area = int(mask.sum())\n",
        "        \n",
        "        if area > 0:\n",
        "            prob_resized = cv2.resize(prob, pil.size, interpolation=cv2.INTER_LINEAR)\n",
        "            mean_inside = float(prob_resized[mask == 1].mean())\n",
        "        else:\n",
        "            mean_inside = 0.0\n",
        "        \n",
        "        # Filter out small/weak detections\n",
        "        if area >= 400 and mean_inside >= 0.35:\n",
        "            all_masks.append(mask)\n",
        "            all_areas.append(area)\n",
        "            all_means.append(mean_inside)\n",
        "            all_thrs.append(thr)\n",
        "    \n",
        "    if len(all_masks) == 0:\n",
        "        # No valid masks found\n",
        "        return \"authentic\", [], {\"area\": 0, \"mean_inside\": 0.0, \"thr\": 0.0}\n",
        "    \n",
        "    total_area = sum(all_areas)\n",
        "    avg_mean = sum(all_means) / len(all_means)\n",
        "    avg_thr = sum(all_thrs) / len(all_thrs)\n",
        "    \n",
        "    return \"forged\", all_masks, {\"area\": total_area, \"mean_inside\": avg_mean, \"thr\": avg_thr, \"num_masks\": len(all_masks)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a9fc331",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import numba\n",
        "import numpy as np\n",
        "from numba import types\n",
        "import numpy.typing as npt\n",
        "import pandas as pd\n",
        "import scipy.optimize\n",
        "import torch\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "\n",
        "class ParticipantVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "@numba.jit(nopython=True)\n",
        "def _rle_encode_jit(x: npt.NDArray, fg_val: int = 1) -> list[int]:\n",
        "    \"\"\"Numba-jitted RLE encoder.\"\"\"\n",
        "    dots = np.where(x.T.flatten() == fg_val)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if b > prev + 1:\n",
        "            run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths\n",
        "\n",
        "\n",
        "def rle_encode(masks: list[npt.NDArray], fg_val: int = 1) -> str:\n",
        "    \"\"\"\n",
        "    Adapted from contrails RLE https://www.kaggle.com/code/inversion/contrails-rle-submission\n",
        "    Args:\n",
        "        masks: list of numpy array of shape (height, width), 1 - mask, 0 - background\n",
        "    Returns: run length encodings as a string, with each RLE JSON-encoded and separated by a semicolon.\n",
        "    \"\"\"\n",
        "    return ';'.join([json.dumps(_rle_encode_jit(x, fg_val)) for x in masks])\n",
        "\n",
        "\n",
        "@numba.njit\n",
        "def _rle_decode_jit(mask_rle: npt.NDArray, height: int, width: int) -> npt.NDArray:\n",
        "    \"\"\"\n",
        "    s: numpy array of run-length encoding pairs (start, length)\n",
        "    shape: (height, width) of array to return\n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "    \"\"\"\n",
        "    if len(mask_rle) % 2 != 0:\n",
        "        # Numba requires raising a standard exception.\n",
        "        raise ValueError('One or more rows has an odd number of values.')\n",
        "\n",
        "    starts, lengths = mask_rle[0::2], mask_rle[1::2]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    for i in range(len(starts) - 1):\n",
        "        if ends[i] > starts[i + 1]:\n",
        "            raise ValueError('Pixels must not be overlapping.')\n",
        "    img = np.zeros(height * width, dtype=np.bool_)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img\n",
        "\n",
        "\n",
        "def rle_decode(mask_rle: str, shape: tuple[int, int]) -> npt.NDArray:\n",
        "    \"\"\"\n",
        "    mask_rle: run-length as string formatted (start length)\n",
        "              empty predictions need to be encoded with '-'\n",
        "    shape: (height, width) of array to return\n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "    \"\"\"\n",
        "\n",
        "    mask_rle = json.loads(mask_rle)\n",
        "    mask_rle = np.asarray(mask_rle, dtype=np.int32)\n",
        "    starts = mask_rle[0::2]\n",
        "    if sorted(starts) != list(starts):\n",
        "        raise ParticipantVisibleError('Submitted values must be in ascending order.')\n",
        "    try:\n",
        "        return _rle_decode_jit(mask_rle, shape[0], shape[1]).reshape(shape, order='F')\n",
        "    except ValueError as e:\n",
        "        raise ParticipantVisibleError(str(e)) from e\n",
        "\n",
        "\n",
        "# ===================== GPU-ACCELERATED SCORING FUNCTIONS =====================\n",
        "\n",
        "def calculate_f1_matrix_gpu(pred_masks: list[npt.NDArray], gt_masks: list[npt.NDArray], device='cuda'):\n",
        "    \"\"\"\n",
        "    GPU-accelerated F1 matrix calculation.\n",
        "    Computes F1 scores for all pairs of predicted and ground truth masks in parallel.\n",
        "    \n",
        "    Parameters:\n",
        "    pred_masks: List of predicted binary masks (each is height x width)\n",
        "    gt_masks: List of ground truth binary masks (each is height x width)\n",
        "    device: 'cuda' or 'cpu'\n",
        "    \n",
        "    Returns:\n",
        "    numpy array of shape (num_pred, num_gt) containing F1 scores\n",
        "    \"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        device = 'cpu'\n",
        "    \n",
        "    num_pred = len(pred_masks)\n",
        "    num_gt = len(gt_masks)\n",
        "    \n",
        "    if num_pred == 0 or num_gt == 0:\n",
        "        return np.zeros((max(num_pred, num_gt), num_gt))\n",
        "    \n",
        "    # Stack and flatten masks, convert to GPU tensors\n",
        "    # Shape: (num_pred, H*W) and (num_gt, H*W)\n",
        "    pred_flat = torch.stack([torch.from_numpy(m.flatten().astype(np.float32)) for m in pred_masks]).to(device)\n",
        "    gt_flat = torch.stack([torch.from_numpy(m.flatten().astype(np.float32)) for m in gt_masks]).to(device)\n",
        "    \n",
        "    # Expand dims for broadcasting: pred (num_pred, 1, H*W), gt (1, num_gt, H*W)\n",
        "    pred_expanded = pred_flat.unsqueeze(1)  # (num_pred, 1, H*W)\n",
        "    gt_expanded = gt_flat.unsqueeze(0)       # (1, num_gt, H*W)\n",
        "    \n",
        "    # Compute TP, FP, FN for all pairs at once using broadcasting\n",
        "    # This creates (num_pred, num_gt, H*W) intermediate tensors\n",
        "    tp = torch.sum((pred_expanded == 1) & (gt_expanded == 1), dim=2).float()  # (num_pred, num_gt)\n",
        "    fp = torch.sum((pred_expanded == 1) & (gt_expanded == 0), dim=2).float()\n",
        "    fn = torch.sum((pred_expanded == 0) & (gt_expanded == 1), dim=2).float()\n",
        "    \n",
        "    # Compute precision and recall\n",
        "    precision = tp / (tp + fp + 1e-10)\n",
        "    recall = tp / (tp + fn + 1e-10)\n",
        "    \n",
        "    # Handle edge cases where tp + fp or tp + fn is 0\n",
        "    precision = torch.where((tp + fp) > 0, precision, torch.zeros_like(precision))\n",
        "    recall = torch.where((tp + fn) > 0, recall, torch.zeros_like(recall))\n",
        "    \n",
        "    # Compute F1\n",
        "    f1_matrix = 2 * precision * recall / (precision + recall + 1e-10)\n",
        "    f1_matrix = torch.where((precision + recall) > 0, f1_matrix, torch.zeros_like(f1_matrix))\n",
        "    \n",
        "    f1_matrix = f1_matrix.cpu().numpy()\n",
        "    \n",
        "    # Pad if needed\n",
        "    if f1_matrix.shape[0] < num_gt:\n",
        "        f1_matrix = np.vstack((f1_matrix, np.zeros((num_gt - f1_matrix.shape[0], num_gt))))\n",
        "    \n",
        "    return f1_matrix\n",
        "\n",
        "\n",
        "def calculate_f1_matrix_gpu_batched(pred_masks: list[npt.NDArray], gt_masks: list[npt.NDArray], \n",
        "                                     device='cuda', batch_size=50):\n",
        "    \"\"\"\n",
        "    Memory-efficient GPU F1 matrix calculation with batching.\n",
        "    Use this for large numbers of masks to avoid GPU OOM.\n",
        "    \"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        device = 'cpu'\n",
        "    \n",
        "    num_pred = len(pred_masks)\n",
        "    num_gt = len(gt_masks)\n",
        "    \n",
        "    if num_pred == 0 or num_gt == 0:\n",
        "        return np.zeros((max(num_pred, num_gt), num_gt))\n",
        "    \n",
        "    # Pre-convert all masks to tensors on GPU\n",
        "    pred_tensors = [torch.from_numpy(m.flatten().astype(np.float32)).to(device) for m in pred_masks]\n",
        "    gt_tensors = [torch.from_numpy(m.flatten().astype(np.float32)).to(device) for m in gt_masks]\n",
        "    \n",
        "    f1_matrix = np.zeros((num_pred, num_gt), dtype=np.float32)\n",
        "    \n",
        "    # Process in batches to avoid OOM\n",
        "    for i_start in range(0, num_pred, batch_size):\n",
        "        i_end = min(i_start + batch_size, num_pred)\n",
        "        pred_batch = torch.stack(pred_tensors[i_start:i_end])  # (batch, H*W)\n",
        "        \n",
        "        for j_start in range(0, num_gt, batch_size):\n",
        "            j_end = min(j_start + batch_size, num_gt)\n",
        "            gt_batch = torch.stack(gt_tensors[j_start:j_end])  # (batch, H*W)\n",
        "            \n",
        "            # Broadcast and compute\n",
        "            pred_exp = pred_batch.unsqueeze(1)  # (batch_pred, 1, H*W)\n",
        "            gt_exp = gt_batch.unsqueeze(0)       # (1, batch_gt, H*W)\n",
        "            \n",
        "            tp = torch.sum((pred_exp == 1) & (gt_exp == 1), dim=2).float()\n",
        "            fp = torch.sum((pred_exp == 1) & (gt_exp == 0), dim=2).float()\n",
        "            fn = torch.sum((pred_exp == 0) & (gt_exp == 1), dim=2).float()\n",
        "            \n",
        "            precision = torch.where((tp + fp) > 0, tp / (tp + fp), torch.zeros_like(tp))\n",
        "            recall = torch.where((tp + fn) > 0, tp / (tp + fn), torch.zeros_like(tp))\n",
        "            \n",
        "            f1 = torch.where((precision + recall) > 0, \n",
        "                            2 * precision * recall / (precision + recall), \n",
        "                            torch.zeros_like(precision))\n",
        "            \n",
        "            f1_matrix[i_start:i_end, j_start:j_end] = f1.cpu().numpy()\n",
        "    \n",
        "    # Pad if needed\n",
        "    if f1_matrix.shape[0] < num_gt:\n",
        "        f1_matrix = np.vstack((f1_matrix, np.zeros((num_gt - f1_matrix.shape[0], num_gt))))\n",
        "    \n",
        "    return f1_matrix\n",
        "\n",
        "\n",
        "def oF1_score_gpu(pred_masks: list[npt.NDArray], gt_masks: list[npt.NDArray], device='cuda'):\n",
        "    \"\"\"\n",
        "    GPU-accelerated optimal F1 score calculation.\n",
        "    Uses GPU for F1 matrix computation, CPU for Hungarian algorithm.\n",
        "    \"\"\"\n",
        "    # Use batched version for memory efficiency\n",
        "    f1_matrix = calculate_f1_matrix_gpu_batched(pred_masks, gt_masks, device=device)\n",
        "    \n",
        "    # Hungarian algorithm runs on CPU (scipy)\n",
        "    row_ind, col_ind = scipy.optimize.linear_sum_assignment(-f1_matrix)\n",
        "    excess_predictions_penalty = len(gt_masks) / max(len(pred_masks), len(gt_masks))\n",
        "    return np.mean(f1_matrix[row_ind, col_ind]) * excess_predictions_penalty\n",
        "\n",
        "\n",
        "def evaluate_single_image_gpu(label_rles: str, prediction_rles: str, shape_str: str, device='cuda') -> float:\n",
        "    \"\"\"GPU-accelerated single image evaluation.\"\"\"\n",
        "    shape = json.loads(shape_str)\n",
        "    label_masks = [rle_decode(x, shape=shape) for x in label_rles.split(';')]\n",
        "    prediction_masks = [rle_decode(x, shape=shape) for x in prediction_rles.split(';')]\n",
        "    return oF1_score_gpu(prediction_masks, label_masks, device=device)\n",
        "\n",
        "\n",
        "def score_gpu(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, \n",
        "              device='cuda', num_workers: int = 1, return_details: bool = True):\n",
        "    \"\"\"\n",
        "    GPU-accelerated scoring function with parallel processing.\n",
        "    \n",
        "    Args:\n",
        "        solution: Ground truth DataFrame\n",
        "        submission: Submission DataFrame  \n",
        "        row_id_column_name: Column name for row IDs\n",
        "        device: 'cuda' or 'cpu'\n",
        "        num_workers: Number of parallel workers for batch processing\n",
        "        return_details: If True, returns (score, details_df) tuple\n",
        "        \n",
        "    Returns:\n",
        "        If return_details=True: (float, pd.DataFrame) - score and detailed results per row\n",
        "        If return_details=False: float - just the score\n",
        "    \"\"\"\n",
        "    import gc\n",
        "    import traceback\n",
        "    \n",
        "    df = solution.copy()\n",
        "    df = df.rename(columns={'annotation': 'label'})\n",
        "    df['prediction'] = submission['annotation']\n",
        "    \n",
        "    # Initialize result columns\n",
        "    df['image_score'] = 0.0\n",
        "    df['success'] = True\n",
        "    df['error_msg'] = ''\n",
        "    df['eval_type'] = 'pending'\n",
        "    df['num_pred_masks'] = 0\n",
        "    df['num_gt_masks'] = 0\n",
        "    df['shape_parsed'] = ''\n",
        "    # Keep existing 'image' column if present, otherwise initialize empty\n",
        "    if 'image' not in df.columns:\n",
        "        df['image'] = ''\n",
        "    \n",
        "    # Identify authentic vs forged\n",
        "    authentic_indices = (df['label'] == 'authentic') | (df['prediction'] == 'authentic')\n",
        "    \n",
        "    # Handle authentic cases\n",
        "    df.loc[authentic_indices, 'image_score'] = ((df['label'] == df['prediction']) & authentic_indices).astype(float)\n",
        "    df.loc[authentic_indices, 'eval_type'] = 'authentic'\n",
        "    \n",
        "    # Get rows that need evaluation\n",
        "    eval_indices = df.loc[~authentic_indices].index.tolist()\n",
        "    \n",
        "    if len(eval_indices) == 0:\n",
        "        final_score = float(np.mean(df['image_score']))\n",
        "        if return_details:\n",
        "            return final_score, df\n",
        "        return final_score\n",
        "    \n",
        "    print(f\"Evaluating {len(eval_indices)} forged images on GPU...\")\n",
        "    \n",
        "    # Process sequentially to better handle memory and catch errors per-row\n",
        "    for idx in tqdm(eval_indices, desc=\"GPU Scoring\"):\n",
        "        row = df.loc[idx]\n",
        "        try:\n",
        "            # Parse shape for debugging\n",
        "            shape = json.loads(row['shape'])\n",
        "            df.loc[idx, 'shape_parsed'] = str(shape)\n",
        "            df.loc[idx, 'image'] = row['image']\n",
        "            \n",
        "            # Count masks\n",
        "            label_rles = row['label'].split(';')\n",
        "            pred_rles = row['prediction'].split(';')\n",
        "            df.loc[idx, 'num_gt_masks'] = len(label_rles)\n",
        "            df.loc[idx, 'num_pred_masks'] = len(pred_rles)\n",
        "            \n",
        "            # Evaluate\n",
        "            result = evaluate_single_image_gpu(row['label'], row['prediction'], row['shape'], device=device)\n",
        "            df.loc[idx, 'image_score'] = result\n",
        "            df.loc[idx, 'eval_type'] = 'forged_evaluated'\n",
        "            df.loc[idx, 'success'] = True\n",
        "            \n",
        "        except torch.cuda.OutOfMemoryError as e:\n",
        "            df.loc[idx, 'success'] = False\n",
        "            df.loc[idx, 'error_msg'] = f\"CUDA OOM: {str(e)}\"\n",
        "            df.loc[idx, 'eval_type'] = 'error_oom'\n",
        "            df.loc[idx, 'image_score'] = 0.0\n",
        "            print(f\"\\nâš ï¸ CUDA OOM at index {idx}: {str(e)[:100]}\")\n",
        "            # Try to recover\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            \n",
        "        except Exception as e:\n",
        "            df.loc[idx, 'success'] = False\n",
        "            df.loc[idx, 'error_msg'] = f\"{type(e).__name__}: {str(e)}\"\n",
        "            df.loc[idx, 'eval_type'] = 'error_other'\n",
        "            df.loc[idx, 'image_score'] = 0.0\n",
        "            print(f\"\\nâš ï¸ Error at index {idx}: {type(e).__name__}: {str(e)[:100]}\")\n",
        "            \n",
        "        # Periodically clear GPU cache\n",
        "        if idx % 50 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "    \n",
        "    final_score = float(np.mean(df['image_score']))\n",
        "    \n",
        "    # Print summary\n",
        "    num_success = df['success'].sum()\n",
        "    num_failed = (~df['success']).sum()\n",
        "    print(f\"\\nâœ… Completed: {num_success} succeeded, {num_failed} failed\")\n",
        "    print(f\"ðŸ“Š Final score: {final_score:.4f}\")\n",
        "    \n",
        "    if return_details:\n",
        "        return final_score, df\n",
        "    return final_score\n",
        "\n",
        "\n",
        "# ===================== LEGACY CPU FUNCTIONS (kept for compatibility) =====================\n",
        "\n",
        "def calculate_f1_score(pred_mask: npt.NDArray, gt_mask: npt.NDArray):\n",
        "    pred_flat = pred_mask.flatten()\n",
        "    gt_flat = gt_mask.flatten()\n",
        "\n",
        "    tp = np.sum((pred_flat == 1) & (gt_flat == 1))\n",
        "    fp = np.sum((pred_flat == 1) & (gt_flat == 0))\n",
        "    fn = np.sum((pred_flat == 0) & (gt_flat == 1))\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "    if (precision + recall) > 0:\n",
        "        return 2 * (precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def calculate_f1_matrix(pred_masks: list[npt.NDArray], gt_masks: list[npt.NDArray]):\n",
        "    \"\"\"CPU version - use calculate_f1_matrix_gpu for faster processing.\"\"\"\n",
        "    num_instances_pred = len(pred_masks)\n",
        "    num_instances_gt = len(gt_masks)\n",
        "    f1_matrix = np.zeros((num_instances_pred, num_instances_gt))\n",
        "\n",
        "    for i in range(num_instances_pred):\n",
        "        for j in range(num_instances_gt):\n",
        "            pred_flat = pred_masks[i].flatten()\n",
        "            gt_flat = gt_masks[j].flatten()\n",
        "            f1_matrix[i, j] = calculate_f1_score(pred_mask=pred_flat, gt_mask=gt_flat)\n",
        "\n",
        "    if f1_matrix.shape[0] < len(gt_masks):\n",
        "        f1_matrix = np.vstack((f1_matrix, np.zeros((len(gt_masks) - len(f1_matrix), num_instances_gt))))\n",
        "\n",
        "    return f1_matrix\n",
        "\n",
        "\n",
        "def oF1_score(pred_masks: list[npt.NDArray], gt_masks: list[npt.NDArray]):\n",
        "    \"\"\"CPU version - use oF1_score_gpu for faster processing.\"\"\"\n",
        "    f1_matrix = calculate_f1_matrix(pred_masks, gt_masks)\n",
        "    row_ind, col_ind = scipy.optimize.linear_sum_assignment(-f1_matrix)\n",
        "    excess_predictions_penalty = len(gt_masks) / max(len(pred_masks), len(gt_masks))\n",
        "    return np.mean(f1_matrix[row_ind, col_ind]) * excess_predictions_penalty\n",
        "\n",
        "\n",
        "def evaluate_single_image(label_rles: str, prediction_rles: str, shape_str: str) -> float:\n",
        "    shape = json.loads(shape_str)\n",
        "    label_rles = [rle_decode(x, shape=shape) for x in label_rles.split(';')]\n",
        "    prediction_rles = [rle_decode(x, shape=shape) for x in prediction_rles.split(';')]\n",
        "    return oF1_score(prediction_rles, label_rles)\n",
        "\n",
        "\n",
        "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
        "    \"\"\"CPU version - use score_gpu for faster processing.\"\"\"\n",
        "    df = solution\n",
        "    df = df.rename(columns={'annotation': 'label'})\n",
        "\n",
        "    df['prediction'] = submission['annotation']\n",
        "    authentic_indices = (df['label'] == 'authentic') | (df['prediction'] == 'authentic')\n",
        "    df['image_score'] = ((df['label'] == df['prediction']) & authentic_indices).astype(float)\n",
        "\n",
        "    def eval_wrapped(row):\n",
        "        result = evaluate_single_image(row['label'], row['prediction'], row['shape'])\n",
        "        print(f\"finished one image, image_score: {result}\")\n",
        "        return result\n",
        "\n",
        "    df.loc[~authentic_indices, 'image_score'] = df.loc[~authentic_indices].apply(\n",
        "        eval_wrapped, axis=1\n",
        "    )\n",
        "    return float(np.mean(df['image_score']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2ce2a8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "solution = []\n",
        "submission = []\n",
        "\n",
        "val_items = [(p, \"forged\") for p in val_forg]\n",
        "val_items += [(p, \"authentic\") for p in val_auth]\n",
        "results = []\n",
        "\n",
        "for p, status in tqdm(val_items, desc=\"Validation forged-only\"):\n",
        "    pil = Image.open(p).convert(\"RGB\")\n",
        "    label, masks_pred, dbg = pipeline_final(pil)  # masks_pred is now a LIST of masks\n",
        "\n",
        "    m_gt = np.load(Path(MASK_DIR)/f\"{Path(p).stem}.npy\")\n",
        "    \n",
        "    # Convert ground truth to list if it's 3D (N, H, W), otherwise wrap in list\n",
        "    if m_gt.ndim == 3:\n",
        "        gt_masks_list = [m_gt[i] for i in range(m_gt.shape[0])]\n",
        "        our_shape = m_gt.shape[1:]\n",
        "    else:\n",
        "        gt_masks_list = [m_gt]\n",
        "        our_shape = m_gt.shape\n",
        "    \n",
        "    # Prepare predicted masks list - resize to match ground truth shape if needed\n",
        "    if label == \"authentic\" or len(masks_pred) == 0:\n",
        "        pred_masks_list = []\n",
        "    else:\n",
        "        pred_masks_list = []\n",
        "        for m in masks_pred:\n",
        "            m_resized = cv2.resize((m > 0).astype(np.uint8), (our_shape[1], our_shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "            if m_resized.sum() > 0:  # Only add non-empty masks\n",
        "                pred_masks_list.append(m_resized)\n",
        "    \n",
        "    # Encode using the list-based rle_encode (joins with ';')\n",
        "    solution_ann = \"authentic\" if status == \"authentic\" else rle_encode(gt_masks_list)\n",
        "    submission_ann = \"authentic\" if len(pred_masks_list) == 0 else rle_encode(pred_masks_list)\n",
        "\n",
        "    solution.append({ \"annotation\": str(solution_ann), \"shape\": str(list(our_shape)), \"image\": p})\n",
        "    submission.append({ \"annotation\": str(submission_ann), \"shape\": str(list(our_shape)), \"image\": p})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e42e8acf",
      "metadata": {},
      "outputs": [],
      "source": [
        "submissionDF = pd.DataFrame(submission)\n",
        "solutionDF = pd.DataFrame(solution)\n",
        "# make row_id column\n",
        "submissionDF['row_id'] = submissionDF.index\n",
        "solutionDF['row_id'] = solutionDF.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4e786a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use GPU-accelerated scoring (returns score and detailed results DataFrame)\n",
        "final_score, results_df = score_gpu(solutionDF, submissionDF, \"row_id\", device=device)\n",
        "\n",
        "print(f\"\\nFinal Score: {final_score:.4f}\")\n",
        "\n",
        "# Show failed rows for debugging\n",
        "failed_df = results_df[~results_df['success']]\n",
        "if len(failed_df) > 0:\n",
        "    print(f\"\\nâŒ Failed rows ({len(failed_df)}):\")\n",
        "    print(failed_df[['row_id', 'eval_type', 'error_msg', 'num_gt_masks', 'num_pred_masks', 'shape_parsed']].to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edfc0878",
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f6d7921",
      "metadata": {},
      "outputs": [],
      "source": [
        "index = 984\n",
        "image = Image.open(results_df.iloc[index]['image'])\n",
        "\n",
        "results_df.iloc[index]\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "370ba7a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "our_shape = json.loads(results_df.iloc[index]['shape'])\n",
        "gt_mask = [rle_decode(x, our_shape) for x in results_df.iloc[index]['label'].split(';')][0]\n",
        "pred_mask = [rle_decode(x, our_shape) for x in results_df.iloc[index]['prediction'].split(';')][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d80d5f62",
      "metadata": {},
      "outputs": [],
      "source": [
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13e99496",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(image)\n",
        "plt.imshow(pred_mask, alpha=0.2)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2985451d",
      "metadata": {},
      "outputs": [],
      "source": [
        "submissionDF[submissionDF.row_id ==40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cc1b343",
      "metadata": {},
      "outputs": [],
      "source": [
        "submissionDF.iloc[2]['annotation'].split(';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f35d4d01",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-11T01:39:57.424783Z",
          "iopub.status.busy": "2025-11-11T01:39:57.424007Z",
          "iopub.status.idle": "2025-11-11T01:39:58.507865Z",
          "shell.execute_reply": "2025-11-11T01:39:58.507093Z"
        },
        "papermill": {
          "duration": 1.818846,
          "end_time": "2025-11-11T01:39:58.509513",
          "exception": false,
          "start_time": "2025-11-11T01:39:56.690667",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os, json, cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- RLE Encoder for Kaggle Submission (handles MULTIPLE masks) ---\n",
        "def rle_encode_single(mask: np.ndarray, fg_val: int = 1) -> str:\n",
        "    \"\"\"Encode a single 2D mask to RLE JSON string.\"\"\"\n",
        "    pixels = mask.T.flatten()\n",
        "    dots = np.where(pixels == fg_val)[0]\n",
        "    if len(dots) == 0:\n",
        "        return None  # Empty mask\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if b > prev + 1:\n",
        "            run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return json.dumps([int(x) for x in run_lengths])\n",
        "\n",
        "def rle_encode_multi(masks: list, fg_val: int = 1) -> str:\n",
        "    \"\"\"Encode multiple masks, joining with semicolons (competition format).\"\"\"\n",
        "    encoded = []\n",
        "    for m in masks:\n",
        "        enc = rle_encode_single((m > 0).astype(np.uint8), fg_val)\n",
        "        if enc is not None:\n",
        "            encoded.append(enc)\n",
        "    return ';'.join(encoded) if encoded else \"authentic\"\n",
        "\n",
        "# --- Paths ---\n",
        "TEST_DIR = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/test_images\"\n",
        "SAMPLE_SUB = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/sample_submission.csv\"\n",
        "OUT_PATH = \"submission.csv\"\n",
        "\n",
        "rows = []\n",
        "for f in tqdm(sorted(os.listdir(TEST_DIR)), desc=\"Inference on Test Set\"):\n",
        "    pil = Image.open(Path(TEST_DIR)/f).convert(\"RGB\")\n",
        "    label, masks, dbg = pipeline_final(pil)  # masks is now a LIST of masks\n",
        "\n",
        "    # Annotation finale\n",
        "    if label == \"authentic\" or len(masks) == 0:\n",
        "        annot = \"authentic\"\n",
        "    else:\n",
        "        annot = rle_encode_multi(masks)\n",
        "\n",
        "    rows.append({\n",
        "        \"case_id\": Path(f).stem,\n",
        "        \"annotation\": annot,\n",
        "        \"area\": int(dbg.get(\"area\", 0)),\n",
        "        \"mean\": float(dbg.get(\"mean_inside\", 0.0)),\n",
        "        \"thr\": float(dbg.get(\"thr\", 0.0)),\n",
        "        \"num_masks\": int(dbg.get(\"num_masks\", len(masks) if masks else 0))\n",
        "    })\n",
        "\n",
        "\n",
        "sub = pd.DataFrame(rows)\n",
        "ss = pd.read_csv(SAMPLE_SUB)\n",
        "ss[\"case_id\"] = ss[\"case_id\"].astype(str)\n",
        "sub[\"case_id\"] = sub[\"case_id\"].astype(str)\n",
        "final = ss[[\"case_id\"]].merge(sub, on=\"case_id\", how=\"left\")\n",
        "final[\"annotation\"] = final[\"annotation\"].fillna(\"authentic\")\n",
        "final[[\"case_id\", \"annotation\"]].to_csv(OUT_PATH, index=False)\n",
        "\n",
        "print(f\"\\nâœ… Saved submission file: {OUT_PATH}\")\n",
        "print(final.head(10))\n",
        "\n",
        "\n",
        "sample_files = sorted(os.listdir(TEST_DIR))[:5]\n",
        "for f in sample_files:\n",
        "    pil = Image.open(Path(TEST_DIR)/f).convert(\"RGB\")\n",
        "    label, masks, dbg = pipeline_final(pil)\n",
        "    \n",
        "    # Combine all masks for visualization (overlay them)\n",
        "    if label == \"authentic\" or len(masks) == 0:\n",
        "        combined_mask = np.zeros(pil.size[::-1], np.uint8)\n",
        "    else:\n",
        "        combined_mask = np.zeros(pil.size[::-1], np.uint8)\n",
        "        for m in masks:\n",
        "            combined_mask = np.maximum(combined_mask, (m > 0).astype(np.uint8))\n",
        "\n",
        "    print(f\"{'ðŸ”´' if label=='forged' else 'ðŸŸ¢'} {f}: {label} | area={dbg.get('area', 0)} mean={dbg.get('mean_inside', 0):.3f} | num_masks={len(masks) if masks else 0}\")\n",
        "\n",
        "    if label == \"authentic\":\n",
        "        plt.figure(figsize=(5,5))\n",
        "        plt.imshow(pil)\n",
        "        plt.title(f\"{f} â€” Authentic\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.imshow(pil)\n",
        "        plt.title(\"Original Image\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.imshow(pil)\n",
        "        plt.imshow(combined_mask, alpha=0.45, cmap=\"Reds\")\n",
        "        plt.title(f\"Predicted Forged Masks ({len(masks)})\\nArea={dbg.get('area', 0)} | Mean={dbg.get('mean_inside', 0):.3f}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 14174843,
          "isSourceIdPinned": false,
          "sourceId": 113558,
          "sourceType": "competition"
        },
        {
          "isSourceIdPinned": false,
          "modelId": 986,
          "modelInstanceId": 3326,
          "sourceId": 4534,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 31154,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 6449.810614,
      "end_time": "2025-11-11T01:40:11.393133",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-11-10T23:52:41.582519",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
