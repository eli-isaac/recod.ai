{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Submission Notebook - DINOv2 Forgery Detection\n",
        "\n",
        "This notebook loads pre-trained weights and generates predictions for the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, cv2, json, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoImageProcessor, AutoModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== CONFIG ====================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Kaggle paths\n",
        "TEST_DIR = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/test_images\"\n",
        "SAMPLE_SUB = \"/kaggle/input/recodai-luc-scientific-image-forgery-detection/sample_submission.csv\"\n",
        "\n",
        "# Path to your uploaded model weights dataset\n",
        "# Change this to match your Kaggle dataset name!\n",
        "WEIGHTS_PATH = \"/kaggle/input/your-model-weights-dataset/model_seg_final.pt\"\n",
        "\n",
        "# Model config (must match training)\n",
        "DINO_PATH = \"facebook/dinov2-base\"\n",
        "IMG_SIZE = 512\n",
        "CHANNELS = 4\n",
        "\n",
        "OUT_PATH = \"submission.csv\"\n",
        "\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== MODEL DEFINITION ====================\n",
        "\n",
        "class DinoDecoder(nn.Module):\n",
        "    \"\"\"Progressive upsampling decoder with regularization\"\"\"\n",
        "    def __init__(self, in_ch=768, out_ch=CHANNELS, dropout=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.up1 = self._block(in_ch, 384, dropout)\n",
        "        self.up2 = self._block(384, 192, dropout)\n",
        "        self.up3 = self._block(192, 96, dropout)\n",
        "        self.up4 = self._block(96, 48, dropout)\n",
        "        \n",
        "        self.final = nn.Conv2d(48, out_ch, kernel_size=1)\n",
        "    \n",
        "    def _block(self, in_ch, out_ch, dropout):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    \n",
        "    def forward(self, f, size):\n",
        "        x = F.interpolate(f, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = self.up1(x)\n",
        "        \n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = self.up2(x)\n",
        "        \n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        x = self.up3(x)\n",
        "        \n",
        "        x = F.interpolate(x, size=size, mode='bilinear', align_corners=False)\n",
        "        x = self.up4(x)\n",
        "        \n",
        "        return self.final(x)\n",
        "\n",
        "\n",
        "class DinoSegmenter(nn.Module):\n",
        "    def __init__(self, encoder, processor, unfreeze_blocks=3):\n",
        "        super().__init__()\n",
        "        self.encoder, self.processor = encoder, processor\n",
        "        \n",
        "        # Freeze all parameters\n",
        "        for p in self.encoder.parameters():\n",
        "            p.requires_grad = False\n",
        "        \n",
        "        # Unfreeze last N blocks\n",
        "        num_blocks = len(self.encoder.encoder.layer)\n",
        "        for i in range(num_blocks - unfreeze_blocks, num_blocks):\n",
        "            for p in self.encoder.encoder.layer[i].parameters():\n",
        "                p.requires_grad = True\n",
        "        \n",
        "        for p in self.encoder.layernorm.parameters():\n",
        "            p.requires_grad = True\n",
        "        \n",
        "        self.seg_head = DinoDecoder(768, CHANNELS)\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        imgs = (x*255).clamp(0,255).byte().permute(0,2,3,1).cpu().numpy()\n",
        "        inputs = self.processor(images=list(imgs), return_tensors=\"pt\").to(x.device)\n",
        "        with torch.no_grad():\n",
        "            feats = self.encoder(**inputs).last_hidden_state\n",
        "        B, N, C = feats.shape\n",
        "        fmap = feats[:, 1:, :].permute(0, 2, 1)\n",
        "        s = int(math.sqrt(N-1))\n",
        "        fmap = fmap.reshape(B, C, s, s)\n",
        "        return fmap\n",
        "\n",
        "    def forward_seg(self, x):\n",
        "        fmap = self.forward_features(x)\n",
        "        return self.seg_head(fmap, (IMG_SIZE, IMG_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== LOAD MODEL ====================\n",
        "\n",
        "print(\"Loading DINOv2 encoder...\")\n",
        "processor = AutoImageProcessor.from_pretrained(DINO_PATH)\n",
        "encoder = AutoModel.from_pretrained(DINO_PATH).eval().to(device)\n",
        "\n",
        "print(\"Building model...\")\n",
        "model_seg = DinoSegmenter(encoder, processor).to(device)\n",
        "\n",
        "print(f\"Loading weights from {WEIGHTS_PATH}...\")\n",
        "model_seg.load_state_dict(torch.load(WEIGHTS_PATH, map_location=device))\n",
        "model_seg.eval()\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== INFERENCE FUNCTIONS ====================\n",
        "\n",
        "@torch.no_grad()\n",
        "def segment_prob_map_all_channels(pil):\n",
        "    \"\"\"Returns probability maps for ALL channels.\"\"\"\n",
        "    x = torch.from_numpy(np.array(pil.resize((IMG_SIZE, IMG_SIZE)), np.float32)/255.).permute(2,0,1)[None].to(device)\n",
        "    return torch.sigmoid(model_seg.forward_seg(x))[0].cpu().numpy()\n",
        "\n",
        "\n",
        "def enhanced_adaptive_mask(prob, alpha_grad=0.35):\n",
        "    gx = cv2.Sobel(prob, cv2.CV_32F, 1, 0, ksize=3)\n",
        "    gy = cv2.Sobel(prob, cv2.CV_32F, 0, 1, ksize=3)\n",
        "    grad_mag = np.sqrt(gx**2 + gy**2)\n",
        "    grad_norm = grad_mag / (grad_mag.max() + 1e-6)\n",
        "    enhanced = (1 - alpha_grad) * prob + alpha_grad * grad_norm\n",
        "    enhanced = cv2.GaussianBlur(enhanced, (3,3), 0)\n",
        "    thr = np.mean(enhanced) + 0.3 * np.std(enhanced)\n",
        "    mask = (enhanced > thr).astype(np.uint8)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
        "    return mask, thr\n",
        "\n",
        "\n",
        "def finalize_mask(prob, orig_size):\n",
        "    mask, thr = enhanced_adaptive_mask(prob)\n",
        "    mask = cv2.resize(mask, orig_size, interpolation=cv2.INTER_NEAREST)\n",
        "    return mask, thr\n",
        "\n",
        "\n",
        "def pipeline_final(pil):\n",
        "    \"\"\"Returns a LIST of masks (one per detected forged region).\"\"\"\n",
        "    probs = segment_prob_map_all_channels(pil)\n",
        "    \n",
        "    all_masks = []\n",
        "    all_areas = []\n",
        "    all_means = []\n",
        "    all_thrs = []\n",
        "    \n",
        "    for ch in range(probs.shape[0]):\n",
        "        prob = probs[ch]\n",
        "        mask, thr = finalize_mask(prob, pil.size)\n",
        "        area = int(mask.sum())\n",
        "        \n",
        "        if area > 0:\n",
        "            prob_resized = cv2.resize(prob, pil.size, interpolation=cv2.INTER_LINEAR)\n",
        "            mean_inside = float(prob_resized[mask == 1].mean())\n",
        "        else:\n",
        "            mean_inside = 0.0\n",
        "        \n",
        "        # Filter out small/weak detections\n",
        "        if area >= 400 and mean_inside >= 0.35:\n",
        "            all_masks.append(mask)\n",
        "            all_areas.append(area)\n",
        "            all_means.append(mean_inside)\n",
        "            all_thrs.append(thr)\n",
        "    \n",
        "    if len(all_masks) == 0:\n",
        "        return \"authentic\", [], {\"area\": 0, \"mean_inside\": 0.0, \"thr\": 0.0}\n",
        "    \n",
        "    total_area = sum(all_areas)\n",
        "    avg_mean = sum(all_means) / len(all_means)\n",
        "    avg_thr = sum(all_thrs) / len(all_thrs)\n",
        "    \n",
        "    return \"forged\", all_masks, {\"area\": total_area, \"mean_inside\": avg_mean, \"thr\": avg_thr, \"num_masks\": len(all_masks)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== RLE ENCODING ====================\n",
        "\n",
        "def rle_encode_single(mask: np.ndarray, fg_val: int = 1) -> str:\n",
        "    \"\"\"Encode a single 2D mask to RLE JSON string.\"\"\"\n",
        "    pixels = mask.T.flatten()\n",
        "    dots = np.where(pixels == fg_val)[0]\n",
        "    if len(dots) == 0:\n",
        "        return None\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if b > prev + 1:\n",
        "            run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return json.dumps([int(x) for x in run_lengths])\n",
        "\n",
        "\n",
        "def rle_encode_multi(masks: list, fg_val: int = 1) -> str:\n",
        "    \"\"\"Encode multiple masks, joining with semicolons.\"\"\"\n",
        "    encoded = []\n",
        "    for m in masks:\n",
        "        enc = rle_encode_single((m > 0).astype(np.uint8), fg_val)\n",
        "        if enc is not None:\n",
        "            encoded.append(enc)\n",
        "    return ';'.join(encoded) if encoded else \"authentic\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== GENERATE SUBMISSION ====================\n",
        "\n",
        "rows = []\n",
        "test_files = sorted(os.listdir(TEST_DIR))\n",
        "print(f\"Processing {len(test_files)} test images...\")\n",
        "\n",
        "for f in tqdm(test_files, desc=\"Inference\"):\n",
        "    pil = Image.open(Path(TEST_DIR)/f).convert(\"RGB\")\n",
        "    label, masks, dbg = pipeline_final(pil)\n",
        "\n",
        "    if label == \"authentic\" or len(masks) == 0:\n",
        "        annot = \"authentic\"\n",
        "    else:\n",
        "        annot = rle_encode_multi(masks)\n",
        "\n",
        "    rows.append({\n",
        "        \"case_id\": Path(f).stem,\n",
        "        \"annotation\": annot,\n",
        "    })\n",
        "\n",
        "# Create submission DataFrame\n",
        "sub = pd.DataFrame(rows)\n",
        "\n",
        "# Merge with sample submission to ensure correct order\n",
        "ss = pd.read_csv(SAMPLE_SUB)\n",
        "ss[\"case_id\"] = ss[\"case_id\"].astype(str)\n",
        "sub[\"case_id\"] = sub[\"case_id\"].astype(str)\n",
        "final = ss[[\"case_id\"]].merge(sub, on=\"case_id\", how=\"left\")\n",
        "final[\"annotation\"] = final[\"annotation\"].fillna(\"authentic\")\n",
        "\n",
        "# Save\n",
        "final[[\"case_id\", \"annotation\"]].to_csv(OUT_PATH, index=False)\n",
        "\n",
        "print(f\"\\nâœ… Saved submission to: {OUT_PATH}\")\n",
        "print(f\"Total rows: {len(final)}\")\n",
        "print(f\"Forged: {(final['annotation'] != 'authentic').sum()}\")\n",
        "print(f\"Authentic: {(final['annotation'] == 'authentic').sum()}\")\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "print(final.head(10))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
